/**
 * Prompt Execution Utilities
 * 
 * This module provides utilities for executing prompts with AI when enabled,
 * or falling back to returning prompts for external execution.
 */

import { getAIExecutor, AIExecutionResult } from './ai-executor.js';
import { isAIExecutionEnabled, loadAIConfig } from '../config/ai-config.js';

export interface PromptExecutionOptions {
  /** Whether to force prompt-only mode regardless of configuration */
  forcePromptOnly?: boolean;
  /** Model to use for AI execution */
  model?: string;
  /** Temperature for AI responses */
  temperature?: number;
  /** Maximum tokens for AI responses */
  maxTokens?: number;
  /** System prompt to use */
  systemPrompt?: string;
  /** Expected response format */
  responseFormat?: 'text' | 'json';
  /** Schema for JSON validation (if responseFormat is 'json') */
  schema?: any;
}

export interface PromptExecutionResult {
  /** The result content (either AI response or formatted prompt) */
  content: string;
  /** Whether the result was generated by AI or is a prompt */
  isAIGenerated: boolean;
  /** AI execution metadata (if AI was used) */
  aiMetadata?: AIExecutionResult['metadata'];
  /** Token usage (if AI was used) */
  usage?: AIExecutionResult['usage'];
  /** Model used (if AI was used) */
  model?: string;
}

/**
 * Execute a prompt with AI if enabled, otherwise return formatted prompt
 */
export async function executePromptWithFallback(
  prompt: string,
  instructions: string,
  options: PromptExecutionOptions = {}
): Promise<PromptExecutionResult> {
  const config = loadAIConfig();
  const shouldUseAI = !options.forcePromptOnly && isAIExecutionEnabled(config);

  if (shouldUseAI) {
    try {
      const executor = getAIExecutor();
      
      if (options.responseFormat === 'json') {
        const execOptions: any = {};
        if (options.model !== undefined) execOptions.model = options.model;
        if (options.temperature !== undefined) execOptions.temperature = options.temperature;
        if (options.maxTokens !== undefined) execOptions.maxTokens = options.maxTokens;
        if (options.systemPrompt !== undefined) execOptions.systemPrompt = options.systemPrompt;

        const result = await executor.executeStructuredPrompt(
          prompt,
          options.schema,
          execOptions
        );

        return {
          content: typeof result.data === 'string' ? result.data : JSON.stringify(result.data, null, 2),
          isAIGenerated: true,
          aiMetadata: result.raw.metadata,
          usage: result.raw.usage,
          model: result.raw.model,
        };
      } else {
        const execOptions: any = {};
        if (options.model !== undefined) execOptions.model = options.model;
        if (options.temperature !== undefined) execOptions.temperature = options.temperature;
        if (options.maxTokens !== undefined) execOptions.maxTokens = options.maxTokens;
        if (options.systemPrompt !== undefined) execOptions.systemPrompt = options.systemPrompt;

        const result = await executor.executePrompt(prompt, execOptions);

        return {
          content: result.content,
          isAIGenerated: true,
          aiMetadata: result.metadata,
          usage: result.usage,
          model: result.model,
        };
      }
    } catch (error) {
      console.error('AI execution failed, falling back to prompt-only mode:', error);
      // Fall through to prompt-only mode
    }
  }

  // Fallback to prompt-only mode
  const formattedPrompt = formatPromptForExternal(prompt, instructions);
  return {
    content: formattedPrompt,
    isAIGenerated: false,
  };
}

/**
 * Format a prompt for external execution
 */
function formatPromptForExternal(prompt: string, instructions: string): string {
  return `${instructions}\n\n${prompt}`;
}

/**
 * Execute a prompt that expects structured ADR suggestions
 */
export async function executeADRSuggestionPrompt(
  prompt: string,
  instructions: string,
  options: PromptExecutionOptions = {}
): Promise<PromptExecutionResult> {
  const systemPrompt = options.systemPrompt || `
You are an expert software architect specializing in Architectural Decision Records (ADRs). 
Analyze the provided context and generate specific, actionable ADR suggestions.
Focus on identifying architectural decisions that need to be documented based on the project context.
Provide clear reasoning for each suggestion and prioritize them by importance.
`;

  return executePromptWithFallback(prompt, instructions, {
    ...options,
    systemPrompt,
    temperature: options.temperature ?? 0.1,
    responseFormat: 'text',
  });
}

/**
 * Execute a prompt that expects to generate actual ADRs
 */
export async function executeADRGenerationPrompt(
  prompt: string,
  instructions: string,
  options: PromptExecutionOptions = {}
): Promise<PromptExecutionResult> {
  const systemPrompt = options.systemPrompt || `
You are an expert software architect who creates comprehensive Architectural Decision Records (ADRs).
Generate well-structured ADRs that follow best practices and include all necessary sections.
Ensure each ADR is complete, actionable, and provides clear guidance for the development team.
Use the standard ADR format with Status, Context, Decision, and Consequences sections.
`;

  return executePromptWithFallback(prompt, instructions, {
    ...options,
    systemPrompt,
    temperature: options.temperature ?? 0.1,
    responseFormat: 'text',
  });
}

/**
 * Execute a prompt for project ecosystem analysis
 */
export async function executeEcosystemAnalysisPrompt(
  prompt: string,
  instructions: string,
  options: PromptExecutionOptions = {}
): Promise<PromptExecutionResult> {
  const systemPrompt = options.systemPrompt || `
You are a senior software architect specializing in technology ecosystem analysis.
Analyze the provided project context to identify technologies, patterns, and architectural decisions.
Provide comprehensive insights about the project's technical landscape and recommendations for improvement.
Focus on practical, actionable insights that can guide architectural decisions.
`;

  return executePromptWithFallback(prompt, instructions, {
    ...options,
    systemPrompt,
    temperature: options.temperature ?? 0.1,
    responseFormat: 'text',
  });
}

/**
 * Execute a prompt for research question generation
 */
export async function executeResearchPrompt(
  prompt: string,
  instructions: string,
  options: PromptExecutionOptions = {}
): Promise<PromptExecutionResult> {
  const systemPrompt = options.systemPrompt || `
You are a research specialist who generates comprehensive research questions and methodologies.
Create detailed research plans that help teams investigate architectural decisions and technologies.
Focus on practical research approaches that can be executed by development teams.
Provide clear guidance on research methods, success criteria, and expected outcomes.
`;

  return executePromptWithFallback(prompt, instructions, {
    ...options,
    systemPrompt,
    temperature: options.temperature ?? 0.2, // Slightly higher for creativity
    responseFormat: 'text',
  });
}

/**
 * Check if AI execution is currently available
 */
export function isAIExecutionAvailable(): boolean {
  try {
    const executor = getAIExecutor();
    return executor.isAvailable();
  } catch {
    return false;
  }
}

/**
 * Get AI execution status for debugging
 */
export function getAIExecutionStatus(): {
  isEnabled: boolean;
  hasApiKey: boolean;
  executionMode: string;
  model: string;
  reason: string | undefined;
} {
  try {
    const config = loadAIConfig();
    const hasApiKey = !!config.apiKey;
    const isEnabled = isAIExecutionEnabled(config);

    let reason: string | undefined = undefined;
    if (!hasApiKey) {
      reason = 'Missing OPENROUTER_API_KEY environment variable';
    } else if (config.executionMode !== 'full') {
      reason = `EXECUTION_MODE is '${config.executionMode}', should be 'full'`;
    }

    return {
      isEnabled,
      hasApiKey,
      executionMode: config.executionMode,
      model: config.defaultModel,
      reason
    };
  } catch (error) {
    return {
      isEnabled: false,
      hasApiKey: false,
      executionMode: 'unknown',
      model: 'unknown',
      reason: `Configuration error: ${error instanceof Error ? error.message : String(error)}`
    };
  }
}

/**
 * Get AI execution status and configuration info (legacy)
 */
export function getAIExecutionInfo(): {
  available: boolean;
  mode: 'full' | 'prompt-only';
  model?: string;
  cacheEnabled?: boolean;
} {
  const config = loadAIConfig();
  const available = isAIExecutionAvailable();

  const result: any = {
    available,
    mode: config.executionMode,
  };

  if (available) {
    result.model = config.defaultModel;
    result.cacheEnabled = config.cacheEnabled;
  }

  return result;
}

/**
 * Format execution result for MCP tool response
 */
export function formatMCPResponse(result: PromptExecutionResult): {
  content: Array<{ type: 'text'; text: string }>;
} {
  let responseText = result.content;

  // Add metadata footer if AI was used
  if (result.isAIGenerated && result.aiMetadata) {
    const metadata = [
      `\n\n---`,
      `**AI Generated Response**`,
      `- Model: ${result.model}`,
      `- Execution Time: ${result.aiMetadata.executionTime}ms`,
      `- Cached: ${result.aiMetadata.cached ? 'Yes' : 'No'}`,
    ];

    if (result.usage) {
      metadata.push(`- Tokens Used: ${result.usage.totalTokens} (${result.usage.promptTokens} prompt + ${result.usage.completionTokens} completion)`);
    }

    responseText += metadata.join('\n');
  }

  return {
    content: [{ type: 'text', text: responseText }],
  };
}
